# run_aliccp_llm_retrieval_with_progressbar.py
# YÃªu cáº§u: pip install pandas numpy tqdm faiss-cpu sentence-transformers torch

import os, json
import numpy as np
import pandas as pd
import faiss
from tqdm import tqdm
from sentence_transformers import SentenceTransformer, InputExample, losses, datasets
import torch

# KÃ­ch hoáº¡t tqdm cho cÃ¡c hÃ m apply cá»§a pandas
tqdm.pandas(desc="Processing Prompts")


# ----------------- Prompt builders -----------------
def build_user_prompt(row: pd.Series) -> str:
    # ... (giá»¯ nguyÃªn nhÆ° code gá»‘c)
    return (
        "User Profile:\n"
        f"- MÃ£ khÃ¡ch hÃ ng: {row.get('user_id', 'unk')}\n"
        f"- Tuá»•i: {row.get('age', 'unk')}\n"
        f"- Giá»›i tÃ­nh: {row.get('gender', 'unk')}\n"
        f"- TÃ¬nh tráº¡ng hÃ´n nhÃ¢n: {row.get('marital_status', 'unk')}\n"
        f"- Sá»‘ con: {row.get('num_children', 'unk')}\n"
        f"- NÆ¡i á»Ÿ: {row.get('location', 'unk')}\n"
        f"- Nghá» nghiá»‡p: {row.get('job_title', 'unk')}\n"
        f"- Thu nháº­p/thÃ¡ng: {row.get('income_monthly', 'unk')}\n"
        "Goal: find the most suitable insurance product for this profile."
    )


def build_item_prompt(row: pd.Series) -> str:
    # ... (giá»¯ nguyÃªn nhÆ° code gá»‘c)
    return (
        "Insurance Product:\n"
        f"- MÃ£ sáº£n pháº©m: {row.get('product_id', 'unk')}\n"
        f"- TÃªn sáº£n pháº©m: {row.get('product_name', 'unk')}\n"
        f"- MÃ´ táº£: {row.get('description', 'unk')}\n"
        "Goal: match to users who would benefit most."
    )


# ----------------- Core utils -----------------
def encode_texts(texts, model, batch_size=256, normalize=True):
    # HÃ m encode gá»‘c Ä‘Ã£ cÃ³ show_progress_bar=True, chÃºng ta giá»¯ nguyÃªn
    print(f"ğŸš€ Báº¯t Ä‘áº§u mÃ£ hÃ³a {len(texts)} vÄƒn báº£n...")
    embeddings = model.encode(
        texts, batch_size=batch_size, show_progress_bar=True,
        convert_to_numpy=True, normalize_embeddings=normalize
    )
    print("âœ… MÃ£ hÃ³a hoÃ n táº¥t.")
    return embeddings


def build_faiss_index(item_embs: np.ndarray):
    d = item_embs.shape[1]
    print(f"ğŸ› ï¸ Báº¯t Ä‘áº§u xÃ¢y dá»±ng FAISS index vá»›i {item_embs.shape[0]} vectors (chiá»u: {d})...")
    index = faiss.IndexFlatIP(d)
    index.add(item_embs.astype(np.float32))
    print("âœ… XÃ¢y dá»±ng FAISS index hoÃ n táº¥t.")
    return index


def search_topk(index, q_embs: np.ndarray, topk=10):
    print(f"ğŸ” Báº¯t Ä‘áº§u tÃ¬m kiáº¿m top {topk} cho {q_embs.shape[0]} truy váº¥n...")
    D, I = index.search(q_embs.astype(np.float32), topk)
    print("âœ… TÃ¬m kiáº¿m hoÃ n táº¥t.")
    return D, I


# ----------------- Build training pairs -----------------
def build_training_pairs(users: pd.DataFrame, items: pd.DataFrame):
    """Build InputExample list for training: each (user_prompt, purchased_product_prompt)."""
    item_dict = dict(zip(items["product_id"], items["prompt"]))
    examples = []
    miss = 0
    # ThÃªm tqdm vÃ o vÃ²ng láº·p Ä‘á»ƒ theo dÃµi tiáº¿n trÃ¬nh
    print("ğŸ”„ Báº¯t Ä‘áº§u táº¡o cáº·p dá»¯ liá»‡u huáº¥n luyá»‡n...")
    for _, row in tqdm(users.iterrows(), total=users.shape[0], desc="Creating Training Pairs"):
        pid = row.get("purchased_product_id")
        if pd.isna(pid) or pid not in item_dict:
            miss += 1
            continue
        u_prompt = row["prompt"]
        i_prompt = item_dict[pid]
        examples.append(InputExample(texts=[u_prompt, i_prompt]))
    print(f"âœ… Táº¡o {len(examples)} training pairs (bá» qua {miss} user khÃ´ng cÃ³ product match).")
    return examples


# ----------------- Train function -----------------
from torch.utils.data import DataLoader  # <-- THÃŠM DÃ’NG NÃ€Y


def train_two_tower(model, examples, out_dir, epochs=3, batch_size=32, lr=2e-5):
    # THAY Äá»”I QUAN TRá»ŒNG: Sá»­ dá»¥ng DataLoader tiÃªu chuáº©n cá»§a PyTorch
    # thay vÃ¬ NoDuplicatesDataLoader
    train_dataloader = DataLoader(examples, shuffle=True, batch_size=batch_size)

    train_loss = losses.MultipleNegativesRankingLoss(model)

    print("ğŸ‹ï¸ Báº¯t Ä‘áº§u quÃ¡ trÃ¬nh fine-tuning mÃ´ hÃ¬nh (sá»­ dá»¥ng DataLoader tiÃªu chuáº©n)...")

    # HÃ m fit váº«n giá»¯ nguyÃªn, nhÆ°ng giá» nÃ³ nháº­n DataLoader tiÃªu chuáº©n
    model.fit(
        train_objectives=[(train_dataloader, train_loss)],
        epochs=epochs,
        warmup_steps=int(len(train_dataloader) * 0.1),
        optimizer_params={'lr': lr},
        show_progress_bar=True
    )

    model.save(out_dir)
    print(f"âœ… Model Ä‘Ã£ fine-tune xong vÃ  lÆ°u táº¡i: {out_dir}")
    return model


# ----------------- Main pipeline -----------------
def run_pipeline(
        train_skeleton: str,
        train_common: str,
        out_dir: str = "artifacts_insurance_rs",
        base_model: str = "sentence-transformers/all-MiniLM-L6-v2",
        topk: int = 10,
        do_train: bool = False,
        epochs: int = 3,
        batch_size: int = 32,
        lr: float = 2e-5,
):
    os.makedirs(out_dir, exist_ok=True)

    print("--- BÆ°á»›c 1: Äá»c vÃ  chuáº©n bá»‹ dá»¯ liá»‡u ---")
    users = pd.read_csv(train_skeleton)
    items = pd.read_csv(train_common)
    items = items[["product_id", "product_name", "description"]].drop_duplicates("product_id").reset_index(drop=True)

    print("\n--- BÆ°á»›c 2: Táº¡o prompts tá»« dá»¯ liá»‡u ---")
    # Sá»­ dá»¥ng .progress_apply thay vÃ¬ .apply Ä‘á»ƒ cÃ³ thanh tiáº¿n trÃ¬nh
    users["prompt"] = users.progress_apply(build_user_prompt, axis=1)
    items["prompt"] = items.progress_apply(build_item_prompt, axis=1)

    print("\n--- BÆ°á»›c 3: Táº£i mÃ´ hÃ¬nh Sentence Transformer ---")
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"Sá»­ dá»¥ng thiáº¿t bá»‹: {device}")
    model = SentenceTransformer(base_model, device=device)

    if do_train:
        print("\n--- BÆ°á»›c 4: Huáº¥n luyá»‡n (Fine-tuning) mÃ´ hÃ¬nh ---")
        train_pairs = build_training_pairs(users, items)
        model = train_two_tower(model, train_pairs, out_dir=os.path.join(out_dir, "finetuned_model"),
                                epochs=epochs, batch_size=batch_size, lr=lr)
    else:
        print("\n--- BÆ°á»›c 4: Bá» qua huáº¥n luyá»‡n ---")

    print("\n--- BÆ°á»›c 5: MÃ£ hÃ³a vÄƒn báº£n thÃ nh embeddings ---")
    item_embs = encode_texts(items["prompt"].tolist(), model, batch_size=batch_size)
    user_embs = encode_texts(users["prompt"].tolist(), model, batch_size=batch_size)

    print("\n--- BÆ°á»›c 6: XÃ¢y dá»±ng Index vÃ  TÃ¬m kiáº¿m ---")
    index = build_faiss_index(item_embs)
    D, I = search_topk(index, user_embs, topk=topk)
    item_ids = items["product_id"].tolist()
    item_names = items["product_name"].tolist()

    print("\n--- BÆ°á»›c 7: Tá»•ng há»£p vÃ  lÆ°u káº¿t quáº£ ---")
    recs = []
    # ThÃªm tqdm vÃ o vÃ²ng láº·p cuá»‘i cÃ¹ng
    user_ids = users["user_id"].tolist()
    for i in tqdm(range(len(user_ids)), desc="Generating Recommendations"):
        uid = user_ids[i]
        scores = D[i]
        idxs = I[i]
        recs.append({
            "user_id": uid,
            "rec_product_names": " | ".join(item_names[j] for j in idxs),
            "scores": ",".join(f"{s:.4f}" for s in scores)
        })

    recs_df = pd.DataFrame(recs)
    output_path = os.path.join(out_dir, "recommendations.csv")
    recs_df.to_csv(output_path, index=False)

    print(f"\nâœ… HoÃ n táº¥t! Káº¿t quáº£ gá»£i Ã½ Ä‘Ã£ Ä‘Æ°á»£c lÆ°u táº¡i: {output_path}")
    return recs_df


if __name__ == "__main__":
    # Demo cháº¡y: báº¡n cÃ³ thá»ƒ cháº¡y trá»±c tiáº¿p file Ä‘á»ƒ test
    run_pipeline(
        train_skeleton="data/fake_insurance/raw_customer_and_purchase_data.csv",
        train_common="data/fake_insurance/Train_insurance_products_description.csv",
        out_dir="artifacts_insurance_rs",
        do_train=True,
        epochs=10,
        batch_size=128,  # TÄƒng batch size Ä‘á»ƒ huáº¥n luyá»‡n vÃ  encode nhanh hÆ¡n náº¿u cÃ³ GPU tá»‘t
        lr=2e-5,
        topk=5
    )
