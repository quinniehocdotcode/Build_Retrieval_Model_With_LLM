---
tags:
- sentence-transformers
- sentence-similarity
- feature-extraction
- dense
- generated_from_trainer
- dataset_size:20000
- loss:MultipleNegativesRankingLoss
base_model: sentence-transformers/all-MiniLM-L6-v2
widget:
- source_sentence: 'User Profile:

    - M√£ kh√°ch h√†ng: 4237

    - Tu·ªïi: 62

    - Gi·ªõi t√≠nh: Nam

    - T√¨nh tr·∫°ng h√¥n nh√¢n: ƒê√£ k·∫øt h√¥n

    - S·ªë con: 2

    - N∆°i ·ªü: TP. HCM

    - Ngh·ªÅ nghi·ªáp: K·ªπ s∆∞ ph·∫ßn m·ªÅm

    - Thu nh·∫≠p/th√°ng: 142000000

    Goal: find the most suitable insurance product for this profile.'
  sentences:
  - 'Insurance Product:

    - M√£ s·∫£n ph·∫©m: P01

    - T√™n s·∫£n ph·∫©m: B·∫£o hi·ªÉm S·ª©c kh·ªèe To√†n di·ªán

    - M√¥ t·∫£: ƒê·ªëi t∆∞·ª£ng ph√π h·ª£p: M·ªçi c√° nh√¢n v√† gia ƒë√¨nh mong mu·ªën ƒë∆∞·ª£c b·∫£o v·ªá t√†i
    ch√≠nh tr∆∞·ªõc c√°c r·ªßi ro v·ªÅ s·ª©c kh·ªèe, t·ª´ kh√°m ch·ªØa b·ªánh th√¥ng th∆∞·ªùng ƒë·∫øn ƒëi·ªÅu tr·ªã
    n·ªôi tr√∫ ph·ª©c t·∫°p.

    Quy·ªÅn l·ª£i ch√≠nh:

    - Chi tr·∫£ 100% chi ph√≠ ƒëi·ªÅu tr·ªã n·ªôi tr√∫, ph·∫´u thu·∫≠t, v√† chi ph√≠ ph√≤ng, gi∆∞·ªùng
    b·ªánh.

    - Quy·ªÅn l·ª£i ƒëi·ªÅu tr·ªã ngo·∫°i tr√∫, nha khoa, v√† thai s·∫£n t√πy ch·ªçn.

    - B·∫£o l√£nh vi·ªán ph√≠ t·∫°i h√†ng trƒÉm b·ªánh vi·ªán v√† ph√≤ng kh√°m ch·∫•t l∆∞·ª£ng cao tr√™n
    to√†n qu·ªëc.

    ƒêi·ªÉm n·ªïi b·∫≠t: Th·ªß t·ª•c b·ªìi th∆∞·ªùng nhanh g·ªçn, kh√¥ng gi·ªõi h·∫°n s·ªë l·∫ßn kh√°m ch·ªØa b·ªánh.
    L√† t·∫•m l√° ch·∫Øn t√†i ch√≠nh v·ªØng ch·∫Øc cho s·ª©c kh·ªèe c·ªßa b·∫°n.

    Goal: match to users who would benefit most.'
  - 'Insurance Product:

    - M√£ s·∫£n ph·∫©m: P04

    - T√™n s·∫£n ph·∫©m: B·∫£o hi·ªÉm Li√™n k·∫øt ƒê·∫ßu t∆∞

    - M√¥ t·∫£: ƒê·ªëi t∆∞·ª£ng ph√π h·ª£p: Kh√°ch h√†ng c√≥ kh·∫©u v·ªã r·ªßi ro, am hi·ªÉu v·ªÅ ƒë·∫ßu t∆∞ v√†
    mong mu·ªën gia tƒÉng t√†i s·∫£n m·ªôt c√°ch linh ho·∫°t th√¥ng qua c√°c qu·ªπ ƒë·∫ßu t∆∞ chuy√™n
    nghi·ªáp.

    Quy·ªÅn l·ª£i ch√≠nh:

    - Quy·ªÅn l·ª£i b·∫£o v·ªá nh√¢n th·ªç tr∆∞·ªõc c√°c r·ªßi ro kh√¥ng l∆∞·ªùng tr∆∞·ªõc.

    - Linh ho·∫°t l·ª±a ch·ªçn c√°c qu·ªπ ƒë·∫ßu t∆∞ (c·ªï phi·∫øu, tr√°i phi·∫øu) ƒë·ªÉ t·ªëi ∆∞u h√≥a l·ª£i nhu·∫≠n
    k·ª≥ v·ªçng.

    - D·ªÖ d√†ng thay ƒë·ªïi t·ª∑ l·ªá ph√¢n b·ªï ƒë·∫ßu t∆∞, r√∫t ti·ªÅn, ho·∫∑c ƒë√≥ng th√™m ph√≠ ƒë·ªÉ gia tƒÉng
    gi√° tr·ªã t√†i kho·∫£n.

    ƒêi·ªÉm n·ªïi b·∫≠t: T·ªëi ƒëa h√≥a ti·ªÅm nƒÉng tƒÉng tr∆∞·ªüng t√†i s·∫£n trong d√†i h·∫°n, ƒë·ªìng th·ªùi
    v·∫´n duy tr√¨ m·ªôt l·ªõp b·∫£o v·ªá t√†i ch√≠nh c·ªët l√µi.

    Goal: match to users who would benefit most.'
  - 'Insurance Product:

    - M√£ s·∫£n ph·∫©m: P07

    - T√™n s·∫£n ph·∫©m: B·∫£o hi·ªÉm S·ª©c kh·ªèe cho Gia ƒë√¨nh

    - M√¥ t·∫£: ƒê·ªëi t∆∞·ª£ng ph√π h·ª£p: C√°c gia ƒë√¨nh c√≥ con nh·ªè, mu·ªën b·∫£o v·ªá s·ª©c kh·ªèe cho
    t·∫•t c·∫£ th√†nh vi√™n ch·ªâ trong m·ªôt h·ª£p ƒë·ªìng duy nh·∫•t.

    Quy·ªÅn l·ª£i ch√≠nh:

    - T·∫•t c·∫£ th√†nh vi√™n trong gia ƒë√¨nh (v·ª£, ch·ªìng, con c√°i) ƒë∆∞·ª£c b·∫£o v·ªá chung tr√™n
    m·ªôt h·ª£p ƒë·ªìng.

    - H·∫°n m·ª©c b·∫£o hi·ªÉm chung cho c·∫£ gia ƒë√¨nh ho·∫∑c ri√™ng cho t·ª´ng th√†nh vi√™n.

    - Bao g·ªìm ƒë·∫ßy ƒë·ªß c√°c quy·ªÅn l·ª£i n·ªôi tr√∫, ngo·∫°i tr√∫, nha khoa.

    ƒêi·ªÉm n·ªïi b·∫≠t: Ti·∫øt ki·ªám chi ph√≠ v√† qu·∫£n l√Ω thu·∫≠n ti·ªán h∆°n so v·ªõi vi·ªác mua nhi·ªÅu
    h·ª£p ƒë·ªìng ri√™ng l·∫ª. S·ª± l·ª±a ch·ªçn th√¥ng minh ƒë·ªÉ b·∫£o v·ªá t·ªï ·∫•m c·ªßa b·∫°n.

    Goal: match to users who would benefit most.'
- source_sentence: 'User Profile:

    - M√£ kh√°ch h√†ng: 9027

    - Tu·ªïi: 32

    - Gi·ªõi t√≠nh: N·ªØ

    - T√¨nh tr·∫°ng h√¥n nh√¢n: ƒê·ªôc th√¢n

    - S·ªë con: 0

    - N∆°i ·ªü: H√† N·ªôi

    - Ngh·ªÅ nghi·ªáp: Gi√°o vi√™n

    - Thu nh·∫≠p/th√°ng: 36000000

    Goal: find the most suitable insurance product for this profile.'
  sentences:
  - 'Insurance Product:

    - M√£ s·∫£n ph·∫©m: P06

    - T√™n s·∫£n ph·∫©m: B·∫£o hi·ªÉm Tai n·∫°n C√° nh√¢n

    - M√¥ t·∫£: ƒê·ªëi t∆∞·ª£ng ph√π h·ª£p: M·ªçi ng∆∞·ªùi, ƒë·∫∑c bi·ªát l√† nh·ªØng ng∆∞·ªùi th∆∞·ªùng xuy√™n di
    chuy·ªÉn, l√†m vi·ªác trong m√¥i tr∆∞·ªùng c√≥ r·ªßi ro cao ho·∫∑c tham gia c√°c ho·∫°t ƒë·ªông th·ªÉ
    thao.

    Quy·ªÅn l·ª£i ch√≠nh:

    - Chi tr·∫£ chi ph√≠ y t·∫ø ph√°t sinh do tai n·∫°n.

    - Tr·ª£ c·∫•p thu nh·∫≠p trong th·ªùi gian n·∫±m vi·ªán ƒëi·ªÅu tr·ªã th∆∞∆°ng t·∫≠t do tai n·∫°n.

    - Chi tr·∫£ s·ªë ti·ªÅn b·∫£o hi·ªÉm l·ªõn trong tr∆∞·ªùng h·ª£p t·ª≠ vong ho·∫∑c th∆∞∆°ng t·∫≠t to√†n b·ªô
    vƒ©nh vi·ªÖn do tai n·∫°n.

    ƒêi·ªÉm n·ªïi b·∫≠t: Ph·∫°m vi b·∫£o v·ªá 24/7 tr√™n to√†n th·∫ø gi·ªõi. M·ª©c ph√≠ c·ª±c k·ª≥ th·∫•p nh∆∞ng
    mang l·∫°i s·ª± b·∫£o v·ªá thi·∫øt th·ª±c tr∆∞·ªõc nh·ªØng r·ªßi ro b·∫•t ng·ªù nh·∫•t trong cu·ªôc s·ªëng.

    Goal: match to users who would benefit most.'
  - 'Insurance Product:

    - M√£ s·∫£n ph·∫©m: P01

    - T√™n s·∫£n ph·∫©m: B·∫£o hi·ªÉm S·ª©c kh·ªèe To√†n di·ªán

    - M√¥ t·∫£: ƒê·ªëi t∆∞·ª£ng ph√π h·ª£p: M·ªçi c√° nh√¢n v√† gia ƒë√¨nh mong mu·ªën ƒë∆∞·ª£c b·∫£o v·ªá t√†i
    ch√≠nh tr∆∞·ªõc c√°c r·ªßi ro v·ªÅ s·ª©c kh·ªèe, t·ª´ kh√°m ch·ªØa b·ªánh th√¥ng th∆∞·ªùng ƒë·∫øn ƒëi·ªÅu tr·ªã
    n·ªôi tr√∫ ph·ª©c t·∫°p.

    Quy·ªÅn l·ª£i ch√≠nh:

    - Chi tr·∫£ 100% chi ph√≠ ƒëi·ªÅu tr·ªã n·ªôi tr√∫, ph·∫´u thu·∫≠t, v√† chi ph√≠ ph√≤ng, gi∆∞·ªùng
    b·ªánh.

    - Quy·ªÅn l·ª£i ƒëi·ªÅu tr·ªã ngo·∫°i tr√∫, nha khoa, v√† thai s·∫£n t√πy ch·ªçn.

    - B·∫£o l√£nh vi·ªán ph√≠ t·∫°i h√†ng trƒÉm b·ªánh vi·ªán v√† ph√≤ng kh√°m ch·∫•t l∆∞·ª£ng cao tr√™n
    to√†n qu·ªëc.

    ƒêi·ªÉm n·ªïi b·∫≠t: Th·ªß t·ª•c b·ªìi th∆∞·ªùng nhanh g·ªçn, kh√¥ng gi·ªõi h·∫°n s·ªë l·∫ßn kh√°m ch·ªØa b·ªánh.
    L√† t·∫•m l√° ch·∫Øn t√†i ch√≠nh v·ªØng ch·∫Øc cho s·ª©c kh·ªèe c·ªßa b·∫°n.

    Goal: match to users who would benefit most.'
  - 'Insurance Product:

    - M√£ s·∫£n ph·∫©m: P03

    - T√™n s·∫£n ph·∫©m: B·∫£o hi·ªÉm Nh√¢n th·ªç T√≠ch l≈©y

    - M√¥ t·∫£: ƒê·ªëi t∆∞·ª£ng ph√π h·ª£p: Nh·ªØng ng∆∞·ªùi c√≥ k·∫ø ho·∫°ch t√†i ch√≠nh d√†i h·∫°n, v·ª´a mu·ªën
    ƒë∆∞·ª£c b·∫£o v·ªá tr∆∞·ªõc r·ªßi ro t·ª≠ vong ho·∫∑c th∆∞∆°ng t·∫≠t, v·ª´a mu·ªën x√¢y d·ª±ng m·ªôt qu·ªπ ti·∫øt
    ki·ªám c√≥ k·ª∑ lu·∫≠t.

    Quy·ªÅn l·ª£i ch√≠nh:

    - B·∫£o v·ªá t√†i ch√≠nh cho gia ƒë√¨nh tr∆∞·ªõc r·ªßi ro t·ª≠ vong ho·∫∑c th∆∞∆°ng t·∫≠t to√†n b·ªô vƒ©nh
    vi·ªÖn c·ªßa ng∆∞·ªùi ƒë∆∞·ª£c b·∫£o hi·ªÉm.

    - Nh·∫≠n l·∫°i to√†n b·ªô gi√° tr·ªã t√†i kho·∫£n h·ª£p ƒë·ªìng khi ƒë√°o h·∫°n, bao g·ªìm g·ªëc v√† l√£i
    t√≠ch l≈©y.

    - C√°c kho·∫£n th∆∞·ªüng duy tr√¨ h·ª£p ƒë·ªìng ƒë·ªãnh k·ª≥ h·∫•p d·∫´n.

    ƒêi·ªÉm n·ªïi b·∫≠t: Gi·∫£i ph√°p 2 trong 1: B·∫£o v·ªá v·ªØng ch·∫Øc v√† T√≠ch l≈©y an to√†n. X√¢y d·ª±ng
    t∆∞∆°ng lai b·ªÅn v·ªØng cho b·∫£n th√¢n v√† nh·ªØng ng∆∞·ªùi th√¢n y√™u.

    Goal: match to users who would benefit most.'
- source_sentence: 'User Profile:

    - M√£ kh√°ch h√†ng: 16126

    - Tu·ªïi: 20

    - Gi·ªõi t√≠nh: Nam

    - T√¨nh tr·∫°ng h√¥n nh√¢n: ƒê·ªôc th√¢n

    - S·ªë con: 0

    - N∆°i ·ªü: H·∫£i Ph√≤ng

    - Ngh·ªÅ nghi·ªáp: K·ªπ s∆∞ ph·∫ßn m·ªÅm

    - Thu nh·∫≠p/th√°ng: 39000000

    Goal: find the most suitable insurance product for this profile.'
  sentences:
  - 'Insurance Product:

    - M√£ s·∫£n ph·∫©m: P04

    - T√™n s·∫£n ph·∫©m: B·∫£o hi·ªÉm Li√™n k·∫øt ƒê·∫ßu t∆∞

    - M√¥ t·∫£: ƒê·ªëi t∆∞·ª£ng ph√π h·ª£p: Kh√°ch h√†ng c√≥ kh·∫©u v·ªã r·ªßi ro, am hi·ªÉu v·ªÅ ƒë·∫ßu t∆∞ v√†
    mong mu·ªën gia tƒÉng t√†i s·∫£n m·ªôt c√°ch linh ho·∫°t th√¥ng qua c√°c qu·ªπ ƒë·∫ßu t∆∞ chuy√™n
    nghi·ªáp.

    Quy·ªÅn l·ª£i ch√≠nh:

    - Quy·ªÅn l·ª£i b·∫£o v·ªá nh√¢n th·ªç tr∆∞·ªõc c√°c r·ªßi ro kh√¥ng l∆∞·ªùng tr∆∞·ªõc.

    - Linh ho·∫°t l·ª±a ch·ªçn c√°c qu·ªπ ƒë·∫ßu t∆∞ (c·ªï phi·∫øu, tr√°i phi·∫øu) ƒë·ªÉ t·ªëi ∆∞u h√≥a l·ª£i nhu·∫≠n
    k·ª≥ v·ªçng.

    - D·ªÖ d√†ng thay ƒë·ªïi t·ª∑ l·ªá ph√¢n b·ªï ƒë·∫ßu t∆∞, r√∫t ti·ªÅn, ho·∫∑c ƒë√≥ng th√™m ph√≠ ƒë·ªÉ gia tƒÉng
    gi√° tr·ªã t√†i kho·∫£n.

    ƒêi·ªÉm n·ªïi b·∫≠t: T·ªëi ƒëa h√≥a ti·ªÅm nƒÉng tƒÉng tr∆∞·ªüng t√†i s·∫£n trong d√†i h·∫°n, ƒë·ªìng th·ªùi
    v·∫´n duy tr√¨ m·ªôt l·ªõp b·∫£o v·ªá t√†i ch√≠nh c·ªët l√µi.

    Goal: match to users who would benefit most.'
  - 'Insurance Product:

    - M√£ s·∫£n ph·∫©m: P07

    - T√™n s·∫£n ph·∫©m: B·∫£o hi·ªÉm S·ª©c kh·ªèe cho Gia ƒë√¨nh

    - M√¥ t·∫£: ƒê·ªëi t∆∞·ª£ng ph√π h·ª£p: C√°c gia ƒë√¨nh c√≥ con nh·ªè, mu·ªën b·∫£o v·ªá s·ª©c kh·ªèe cho
    t·∫•t c·∫£ th√†nh vi√™n ch·ªâ trong m·ªôt h·ª£p ƒë·ªìng duy nh·∫•t.

    Quy·ªÅn l·ª£i ch√≠nh:

    - T·∫•t c·∫£ th√†nh vi√™n trong gia ƒë√¨nh (v·ª£, ch·ªìng, con c√°i) ƒë∆∞·ª£c b·∫£o v·ªá chung tr√™n
    m·ªôt h·ª£p ƒë·ªìng.

    - H·∫°n m·ª©c b·∫£o hi·ªÉm chung cho c·∫£ gia ƒë√¨nh ho·∫∑c ri√™ng cho t·ª´ng th√†nh vi√™n.

    - Bao g·ªìm ƒë·∫ßy ƒë·ªß c√°c quy·ªÅn l·ª£i n·ªôi tr√∫, ngo·∫°i tr√∫, nha khoa.

    ƒêi·ªÉm n·ªïi b·∫≠t: Ti·∫øt ki·ªám chi ph√≠ v√† qu·∫£n l√Ω thu·∫≠n ti·ªán h∆°n so v·ªõi vi·ªác mua nhi·ªÅu
    h·ª£p ƒë·ªìng ri√™ng l·∫ª. S·ª± l·ª±a ch·ªçn th√¥ng minh ƒë·ªÉ b·∫£o v·ªá t·ªï ·∫•m c·ªßa b·∫°n.

    Goal: match to users who would benefit most.'
  - 'Insurance Product:

    - M√£ s·∫£n ph·∫©m: P04

    - T√™n s·∫£n ph·∫©m: B·∫£o hi·ªÉm Li√™n k·∫øt ƒê·∫ßu t∆∞

    - M√¥ t·∫£: ƒê·ªëi t∆∞·ª£ng ph√π h·ª£p: Kh√°ch h√†ng c√≥ kh·∫©u v·ªã r·ªßi ro, am hi·ªÉu v·ªÅ ƒë·∫ßu t∆∞ v√†
    mong mu·ªën gia tƒÉng t√†i s·∫£n m·ªôt c√°ch linh ho·∫°t th√¥ng qua c√°c qu·ªπ ƒë·∫ßu t∆∞ chuy√™n
    nghi·ªáp.

    Quy·ªÅn l·ª£i ch√≠nh:

    - Quy·ªÅn l·ª£i b·∫£o v·ªá nh√¢n th·ªç tr∆∞·ªõc c√°c r·ªßi ro kh√¥ng l∆∞·ªùng tr∆∞·ªõc.

    - Linh ho·∫°t l·ª±a ch·ªçn c√°c qu·ªπ ƒë·∫ßu t∆∞ (c·ªï phi·∫øu, tr√°i phi·∫øu) ƒë·ªÉ t·ªëi ∆∞u h√≥a l·ª£i nhu·∫≠n
    k·ª≥ v·ªçng.

    - D·ªÖ d√†ng thay ƒë·ªïi t·ª∑ l·ªá ph√¢n b·ªï ƒë·∫ßu t∆∞, r√∫t ti·ªÅn, ho·∫∑c ƒë√≥ng th√™m ph√≠ ƒë·ªÉ gia tƒÉng
    gi√° tr·ªã t√†i kho·∫£n.

    ƒêi·ªÉm n·ªïi b·∫≠t: T·ªëi ƒëa h√≥a ti·ªÅm nƒÉng tƒÉng tr∆∞·ªüng t√†i s·∫£n trong d√†i h·∫°n, ƒë·ªìng th·ªùi
    v·∫´n duy tr√¨ m·ªôt l·ªõp b·∫£o v·ªá t√†i ch√≠nh c·ªët l√µi.

    Goal: match to users who would benefit most.'
- source_sentence: 'User Profile:

    - M√£ kh√°ch h√†ng: 17390

    - Tu·ªïi: 59

    - Gi·ªõi t√≠nh: Nam

    - T√¨nh tr·∫°ng h√¥n nh√¢n: ƒê√£ k·∫øt h√¥n

    - S·ªë con: 2

    - N∆°i ·ªü: H√† N·ªôi

    - Ngh·ªÅ nghi·ªáp: K·ªπ s∆∞ ph·∫ßn m·ªÅm

    - Thu nh·∫≠p/th√°ng: 49000000

    Goal: find the most suitable insurance product for this profile.'
  sentences:
  - 'Insurance Product:

    - M√£ s·∫£n ph·∫©m: P03

    - T√™n s·∫£n ph·∫©m: B·∫£o hi·ªÉm Nh√¢n th·ªç T√≠ch l≈©y

    - M√¥ t·∫£: ƒê·ªëi t∆∞·ª£ng ph√π h·ª£p: Nh·ªØng ng∆∞·ªùi c√≥ k·∫ø ho·∫°ch t√†i ch√≠nh d√†i h·∫°n, v·ª´a mu·ªën
    ƒë∆∞·ª£c b·∫£o v·ªá tr∆∞·ªõc r·ªßi ro t·ª≠ vong ho·∫∑c th∆∞∆°ng t·∫≠t, v·ª´a mu·ªën x√¢y d·ª±ng m·ªôt qu·ªπ ti·∫øt
    ki·ªám c√≥ k·ª∑ lu·∫≠t.

    Quy·ªÅn l·ª£i ch√≠nh:

    - B·∫£o v·ªá t√†i ch√≠nh cho gia ƒë√¨nh tr∆∞·ªõc r·ªßi ro t·ª≠ vong ho·∫∑c th∆∞∆°ng t·∫≠t to√†n b·ªô vƒ©nh
    vi·ªÖn c·ªßa ng∆∞·ªùi ƒë∆∞·ª£c b·∫£o hi·ªÉm.

    - Nh·∫≠n l·∫°i to√†n b·ªô gi√° tr·ªã t√†i kho·∫£n h·ª£p ƒë·ªìng khi ƒë√°o h·∫°n, bao g·ªìm g·ªëc v√† l√£i
    t√≠ch l≈©y.

    - C√°c kho·∫£n th∆∞·ªüng duy tr√¨ h·ª£p ƒë·ªìng ƒë·ªãnh k·ª≥ h·∫•p d·∫´n.

    ƒêi·ªÉm n·ªïi b·∫≠t: Gi·∫£i ph√°p 2 trong 1: B·∫£o v·ªá v·ªØng ch·∫Øc v√† T√≠ch l≈©y an to√†n. X√¢y d·ª±ng
    t∆∞∆°ng lai b·ªÅn v·ªØng cho b·∫£n th√¢n v√† nh·ªØng ng∆∞·ªùi th√¢n y√™u.

    Goal: match to users who would benefit most.'
  - 'Insurance Product:

    - M√£ s·∫£n ph·∫©m: P05

    - T√™n s·∫£n ph·∫©m: B·∫£o hi·ªÉm H∆∞u tr√≠ An nh√†n

    - M√¥ t·∫£: ƒê·ªëi t∆∞·ª£ng ph√π h·ª£p: Ng∆∞·ªùi lao ƒë·ªông ƒëang trong ƒë·ªô tu·ªïi t√≠ch l≈©y, mong mu·ªën
    c√≥ m·ªôt ngu·ªìn thu nh·∫≠p ·ªïn ƒë·ªãnh v√† ƒë·ªôc l·∫≠p v·ªÅ t√†i ch√≠nh khi v·ªÅ h∆∞u.

    Quy·ªÅn l·ª£i ch√≠nh:

    - T√≠ch l≈©y t√†i s·∫£n m·ªôt c√°ch c√≥ h·ªá th·ªëng trong su·ªët qu√° tr√¨nh l√†m vi·ªác.

    - Nh·∫≠n quy·ªÅn l·ª£i h∆∞u tr√≠ ƒë·ªãnh k·ª≥ (h√†ng th√°ng, h√†ng qu√Ω) sau khi ƒë·∫øn tu·ªïi ngh·ªâ
    h∆∞u.

    - V·∫´n ƒë∆∞·ª£c b·∫£o v·ªá tr∆∞·ªõc r·ªßi ro t·ª≠ vong ho·∫∑c th∆∞∆°ng t·∫≠t trong th·ªùi gian ƒë√≥ng ph√≠.

    ƒêi·ªÉm n·ªïi b·∫≠t: ƒê·∫£m b·∫£o m·ªôt tu·ªïi gi√† an nh√†n, ƒë·ªôc l·∫≠p, kh√¥ng ph·ª• thu·ªôc v√†o con ch√°u.
    B·∫Øt ƒë·∫ßu k·∫ø ho·∫°ch h∆∞u tr√≠ c·ªßa b·∫°n ngay h√¥m nay.

    Goal: match to users who would benefit most.'
  - 'Insurance Product:

    - M√£ s·∫£n ph·∫©m: P01

    - T√™n s·∫£n ph·∫©m: B·∫£o hi·ªÉm S·ª©c kh·ªèe To√†n di·ªán

    - M√¥ t·∫£: ƒê·ªëi t∆∞·ª£ng ph√π h·ª£p: M·ªçi c√° nh√¢n v√† gia ƒë√¨nh mong mu·ªën ƒë∆∞·ª£c b·∫£o v·ªá t√†i
    ch√≠nh tr∆∞·ªõc c√°c r·ªßi ro v·ªÅ s·ª©c kh·ªèe, t·ª´ kh√°m ch·ªØa b·ªánh th√¥ng th∆∞·ªùng ƒë·∫øn ƒëi·ªÅu tr·ªã
    n·ªôi tr√∫ ph·ª©c t·∫°p.

    Quy·ªÅn l·ª£i ch√≠nh:

    - Chi tr·∫£ 100% chi ph√≠ ƒëi·ªÅu tr·ªã n·ªôi tr√∫, ph·∫´u thu·∫≠t, v√† chi ph√≠ ph√≤ng, gi∆∞·ªùng
    b·ªánh.

    - Quy·ªÅn l·ª£i ƒëi·ªÅu tr·ªã ngo·∫°i tr√∫, nha khoa, v√† thai s·∫£n t√πy ch·ªçn.

    - B·∫£o l√£nh vi·ªán ph√≠ t·∫°i h√†ng trƒÉm b·ªánh vi·ªán v√† ph√≤ng kh√°m ch·∫•t l∆∞·ª£ng cao tr√™n
    to√†n qu·ªëc.

    ƒêi·ªÉm n·ªïi b·∫≠t: Th·ªß t·ª•c b·ªìi th∆∞·ªùng nhanh g·ªçn, kh√¥ng gi·ªõi h·∫°n s·ªë l·∫ßn kh√°m ch·ªØa b·ªánh.
    L√† t·∫•m l√° ch·∫Øn t√†i ch√≠nh v·ªØng ch·∫Øc cho s·ª©c kh·ªèe c·ªßa b·∫°n.

    Goal: match to users who would benefit most.'
- source_sentence: 'User Profile:

    - M√£ kh√°ch h√†ng: 8247

    - Tu·ªïi: 36

    - Gi·ªõi t√≠nh: N·ªØ

    - T√¨nh tr·∫°ng h√¥n nh√¢n: ƒê√£ k·∫øt h√¥n

    - S·ªë con: 1

    - N∆°i ·ªü: ƒê√† N·∫µng

    - Ngh·ªÅ nghi·ªáp: Gi√°o vi√™n

    - Thu nh·∫≠p/th√°ng: 99000000

    Goal: find the most suitable insurance product for this profile.'
  sentences:
  - 'Insurance Product:

    - M√£ s·∫£n ph·∫©m: P04

    - T√™n s·∫£n ph·∫©m: B·∫£o hi·ªÉm Li√™n k·∫øt ƒê·∫ßu t∆∞

    - M√¥ t·∫£: ƒê·ªëi t∆∞·ª£ng ph√π h·ª£p: Kh√°ch h√†ng c√≥ kh·∫©u v·ªã r·ªßi ro, am hi·ªÉu v·ªÅ ƒë·∫ßu t∆∞ v√†
    mong mu·ªën gia tƒÉng t√†i s·∫£n m·ªôt c√°ch linh ho·∫°t th√¥ng qua c√°c qu·ªπ ƒë·∫ßu t∆∞ chuy√™n
    nghi·ªáp.

    Quy·ªÅn l·ª£i ch√≠nh:

    - Quy·ªÅn l·ª£i b·∫£o v·ªá nh√¢n th·ªç tr∆∞·ªõc c√°c r·ªßi ro kh√¥ng l∆∞·ªùng tr∆∞·ªõc.

    - Linh ho·∫°t l·ª±a ch·ªçn c√°c qu·ªπ ƒë·∫ßu t∆∞ (c·ªï phi·∫øu, tr√°i phi·∫øu) ƒë·ªÉ t·ªëi ∆∞u h√≥a l·ª£i nhu·∫≠n
    k·ª≥ v·ªçng.

    - D·ªÖ d√†ng thay ƒë·ªïi t·ª∑ l·ªá ph√¢n b·ªï ƒë·∫ßu t∆∞, r√∫t ti·ªÅn, ho·∫∑c ƒë√≥ng th√™m ph√≠ ƒë·ªÉ gia tƒÉng
    gi√° tr·ªã t√†i kho·∫£n.

    ƒêi·ªÉm n·ªïi b·∫≠t: T·ªëi ƒëa h√≥a ti·ªÅm nƒÉng tƒÉng tr∆∞·ªüng t√†i s·∫£n trong d√†i h·∫°n, ƒë·ªìng th·ªùi
    v·∫´n duy tr√¨ m·ªôt l·ªõp b·∫£o v·ªá t√†i ch√≠nh c·ªët l√µi.

    Goal: match to users who would benefit most.'
  - 'Insurance Product:

    - M√£ s·∫£n ph·∫©m: P01

    - T√™n s·∫£n ph·∫©m: B·∫£o hi·ªÉm S·ª©c kh·ªèe To√†n di·ªán

    - M√¥ t·∫£: ƒê·ªëi t∆∞·ª£ng ph√π h·ª£p: M·ªçi c√° nh√¢n v√† gia ƒë√¨nh mong mu·ªën ƒë∆∞·ª£c b·∫£o v·ªá t√†i
    ch√≠nh tr∆∞·ªõc c√°c r·ªßi ro v·ªÅ s·ª©c kh·ªèe, t·ª´ kh√°m ch·ªØa b·ªánh th√¥ng th∆∞·ªùng ƒë·∫øn ƒëi·ªÅu tr·ªã
    n·ªôi tr√∫ ph·ª©c t·∫°p.

    Quy·ªÅn l·ª£i ch√≠nh:

    - Chi tr·∫£ 100% chi ph√≠ ƒëi·ªÅu tr·ªã n·ªôi tr√∫, ph·∫´u thu·∫≠t, v√† chi ph√≠ ph√≤ng, gi∆∞·ªùng
    b·ªánh.

    - Quy·ªÅn l·ª£i ƒëi·ªÅu tr·ªã ngo·∫°i tr√∫, nha khoa, v√† thai s·∫£n t√πy ch·ªçn.

    - B·∫£o l√£nh vi·ªán ph√≠ t·∫°i h√†ng trƒÉm b·ªánh vi·ªán v√† ph√≤ng kh√°m ch·∫•t l∆∞·ª£ng cao tr√™n
    to√†n qu·ªëc.

    ƒêi·ªÉm n·ªïi b·∫≠t: Th·ªß t·ª•c b·ªìi th∆∞·ªùng nhanh g·ªçn, kh√¥ng gi·ªõi h·∫°n s·ªë l·∫ßn kh√°m ch·ªØa b·ªánh.
    L√† t·∫•m l√° ch·∫Øn t√†i ch√≠nh v·ªØng ch·∫Øc cho s·ª©c kh·ªèe c·ªßa b·∫°n.

    Goal: match to users who would benefit most.'
  - 'Insurance Product:

    - M√£ s·∫£n ph·∫©m: P04

    - T√™n s·∫£n ph·∫©m: B·∫£o hi·ªÉm Li√™n k·∫øt ƒê·∫ßu t∆∞

    - M√¥ t·∫£: ƒê·ªëi t∆∞·ª£ng ph√π h·ª£p: Kh√°ch h√†ng c√≥ kh·∫©u v·ªã r·ªßi ro, am hi·ªÉu v·ªÅ ƒë·∫ßu t∆∞ v√†
    mong mu·ªën gia tƒÉng t√†i s·∫£n m·ªôt c√°ch linh ho·∫°t th√¥ng qua c√°c qu·ªπ ƒë·∫ßu t∆∞ chuy√™n
    nghi·ªáp.

    Quy·ªÅn l·ª£i ch√≠nh:

    - Quy·ªÅn l·ª£i b·∫£o v·ªá nh√¢n th·ªç tr∆∞·ªõc c√°c r·ªßi ro kh√¥ng l∆∞·ªùng tr∆∞·ªõc.

    - Linh ho·∫°t l·ª±a ch·ªçn c√°c qu·ªπ ƒë·∫ßu t∆∞ (c·ªï phi·∫øu, tr√°i phi·∫øu) ƒë·ªÉ t·ªëi ∆∞u h√≥a l·ª£i nhu·∫≠n
    k·ª≥ v·ªçng.

    - D·ªÖ d√†ng thay ƒë·ªïi t·ª∑ l·ªá ph√¢n b·ªï ƒë·∫ßu t∆∞, r√∫t ti·ªÅn, ho·∫∑c ƒë√≥ng th√™m ph√≠ ƒë·ªÉ gia tƒÉng
    gi√° tr·ªã t√†i kho·∫£n.

    ƒêi·ªÉm n·ªïi b·∫≠t: T·ªëi ƒëa h√≥a ti·ªÅm nƒÉng tƒÉng tr∆∞·ªüng t√†i s·∫£n trong d√†i h·∫°n, ƒë·ªìng th·ªùi
    v·∫´n duy tr√¨ m·ªôt l·ªõp b·∫£o v·ªá t√†i ch√≠nh c·ªët l√µi.

    Goal: match to users who would benefit most.'
pipeline_tag: sentence-similarity
library_name: sentence-transformers
---

# SentenceTransformer based on sentence-transformers/all-MiniLM-L6-v2

This is a [sentence-transformers](https://www.SBERT.net) model finetuned from [sentence-transformers/all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2). It maps sentences & paragraphs to a 384-dimensional dense vector space and can be used for semantic textual similarity, semantic search, paraphrase mining, text classification, clustering, and more.

## Model Details

### Model Description
- **Model Type:** Sentence Transformer
- **Base model:** [sentence-transformers/all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) <!-- at revision c9745ed1d9f207416be6d2e6f8de32d1f16199bf -->
- **Maximum Sequence Length:** 256 tokens
- **Output Dimensionality:** 384 dimensions
- **Similarity Function:** Cosine Similarity
<!-- - **Training Dataset:** Unknown -->
<!-- - **Language:** Unknown -->
<!-- - **License:** Unknown -->

### Model Sources

- **Documentation:** [Sentence Transformers Documentation](https://sbert.net)
- **Repository:** [Sentence Transformers on GitHub](https://github.com/UKPLab/sentence-transformers)
- **Hugging Face:** [Sentence Transformers on Hugging Face](https://huggingface.co/models?library=sentence-transformers)

### Full Model Architecture

```
SentenceTransformer(
  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False, 'architecture': 'BertModel'})
  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})
  (2): Normalize()
)
```

## Usage

### Direct Usage (Sentence Transformers)

First install the Sentence Transformers library:

```bash
pip install -U sentence-transformers
```

Then you can load this model and run inference.
```python
from sentence_transformers import SentenceTransformer

# Download from the ü§ó Hub
model = SentenceTransformer("sentence_transformers_model_id")
# Run inference
sentences = [
    'User Profile:\n- M√£ kh√°ch h√†ng: 8247\n- Tu·ªïi: 36\n- Gi·ªõi t√≠nh: N·ªØ\n- T√¨nh tr·∫°ng h√¥n nh√¢n: ƒê√£ k·∫øt h√¥n\n- S·ªë con: 1\n- N∆°i ·ªü: ƒê√† N·∫µng\n- Ngh·ªÅ nghi·ªáp: Gi√°o vi√™n\n- Thu nh·∫≠p/th√°ng: 99000000\nGoal: find the most suitable insurance product for this profile.',
    'Insurance Product:\n- M√£ s·∫£n ph·∫©m: P04\n- T√™n s·∫£n ph·∫©m: B·∫£o hi·ªÉm Li√™n k·∫øt ƒê·∫ßu t∆∞\n- M√¥ t·∫£: ƒê·ªëi t∆∞·ª£ng ph√π h·ª£p: Kh√°ch h√†ng c√≥ kh·∫©u v·ªã r·ªßi ro, am hi·ªÉu v·ªÅ ƒë·∫ßu t∆∞ v√† mong mu·ªën gia tƒÉng t√†i s·∫£n m·ªôt c√°ch linh ho·∫°t th√¥ng qua c√°c qu·ªπ ƒë·∫ßu t∆∞ chuy√™n nghi·ªáp.\nQuy·ªÅn l·ª£i ch√≠nh:\n- Quy·ªÅn l·ª£i b·∫£o v·ªá nh√¢n th·ªç tr∆∞·ªõc c√°c r·ªßi ro kh√¥ng l∆∞·ªùng tr∆∞·ªõc.\n- Linh ho·∫°t l·ª±a ch·ªçn c√°c qu·ªπ ƒë·∫ßu t∆∞ (c·ªï phi·∫øu, tr√°i phi·∫øu) ƒë·ªÉ t·ªëi ∆∞u h√≥a l·ª£i nhu·∫≠n k·ª≥ v·ªçng.\n- D·ªÖ d√†ng thay ƒë·ªïi t·ª∑ l·ªá ph√¢n b·ªï ƒë·∫ßu t∆∞, r√∫t ti·ªÅn, ho·∫∑c ƒë√≥ng th√™m ph√≠ ƒë·ªÉ gia tƒÉng gi√° tr·ªã t√†i kho·∫£n.\nƒêi·ªÉm n·ªïi b·∫≠t: T·ªëi ƒëa h√≥a ti·ªÅm nƒÉng tƒÉng tr∆∞·ªüng t√†i s·∫£n trong d√†i h·∫°n, ƒë·ªìng th·ªùi v·∫´n duy tr√¨ m·ªôt l·ªõp b·∫£o v·ªá t√†i ch√≠nh c·ªët l√µi.\nGoal: match to users who would benefit most.',
    'Insurance Product:\n- M√£ s·∫£n ph·∫©m: P01\n- T√™n s·∫£n ph·∫©m: B·∫£o hi·ªÉm S·ª©c kh·ªèe To√†n di·ªán\n- M√¥ t·∫£: ƒê·ªëi t∆∞·ª£ng ph√π h·ª£p: M·ªçi c√° nh√¢n v√† gia ƒë√¨nh mong mu·ªën ƒë∆∞·ª£c b·∫£o v·ªá t√†i ch√≠nh tr∆∞·ªõc c√°c r·ªßi ro v·ªÅ s·ª©c kh·ªèe, t·ª´ kh√°m ch·ªØa b·ªánh th√¥ng th∆∞·ªùng ƒë·∫øn ƒëi·ªÅu tr·ªã n·ªôi tr√∫ ph·ª©c t·∫°p.\nQuy·ªÅn l·ª£i ch√≠nh:\n- Chi tr·∫£ 100% chi ph√≠ ƒëi·ªÅu tr·ªã n·ªôi tr√∫, ph·∫´u thu·∫≠t, v√† chi ph√≠ ph√≤ng, gi∆∞·ªùng b·ªánh.\n- Quy·ªÅn l·ª£i ƒëi·ªÅu tr·ªã ngo·∫°i tr√∫, nha khoa, v√† thai s·∫£n t√πy ch·ªçn.\n- B·∫£o l√£nh vi·ªán ph√≠ t·∫°i h√†ng trƒÉm b·ªánh vi·ªán v√† ph√≤ng kh√°m ch·∫•t l∆∞·ª£ng cao tr√™n to√†n qu·ªëc.\nƒêi·ªÉm n·ªïi b·∫≠t: Th·ªß t·ª•c b·ªìi th∆∞·ªùng nhanh g·ªçn, kh√¥ng gi·ªõi h·∫°n s·ªë l·∫ßn kh√°m ch·ªØa b·ªánh. L√† t·∫•m l√° ch·∫Øn t√†i ch√≠nh v·ªØng ch·∫Øc cho s·ª©c kh·ªèe c·ªßa b·∫°n.\nGoal: match to users who would benefit most.',
]
embeddings = model.encode(sentences)
print(embeddings.shape)
# [3, 384]

# Get the similarity scores for the embeddings
similarities = model.similarity(embeddings, embeddings)
print(similarities)
# tensor([[1.0000, 0.8219, 0.8064],
#         [0.8219, 1.0000, 0.9600],
#         [0.8064, 0.9600, 1.0000]])
```

<!--
### Direct Usage (Transformers)

<details><summary>Click to see the direct usage in Transformers</summary>

</details>
-->

<!--
### Downstream Usage (Sentence Transformers)

You can finetune this model on your own dataset.

<details><summary>Click to expand</summary>

</details>
-->

<!--
### Out-of-Scope Use

*List how the model may foreseeably be misused and address what users ought not to do with the model.*
-->

<!--
## Bias, Risks and Limitations

*What are the known or foreseeable issues stemming from this model? You could also flag here known failure cases or weaknesses of the model.*
-->

<!--
### Recommendations

*What are recommendations with respect to the foreseeable issues? For example, filtering explicit content.*
-->

## Training Details

### Training Dataset

#### Unnamed Dataset

* Size: 20,000 training samples
* Columns: <code>sentence_0</code> and <code>sentence_1</code>
* Approximate statistics based on the first 1000 samples:
  |         | sentence_0                                                                         | sentence_1                                                                            |
  |:--------|:-----------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------|
  | type    | string                                                                             | string                                                                                |
  | details | <ul><li>min: 84 tokens</li><li>mean: 89.81 tokens</li><li>max: 97 tokens</li></ul> | <ul><li>min: 247 tokens</li><li>mean: 255.12 tokens</li><li>max: 256 tokens</li></ul> |
* Samples:
  | sentence_0                                                                                                                                                                                                                                                                                         | sentence_1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |
  |:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
  | <code>User Profile:<br>- M√£ kh√°ch h√†ng: 4210<br>- Tu·ªïi: 47<br>- Gi·ªõi t√≠nh: Nam<br>- T√¨nh tr·∫°ng h√¥n nh√¢n: ƒê√£ k·∫øt h√¥n<br>- S·ªë con: 1<br>- N∆°i ·ªü: H√† N·ªôi<br>- Ngh·ªÅ nghi·ªáp: Sinh vi√™n<br>- Thu nh·∫≠p/th√°ng: 86000000<br>Goal: find the most suitable insurance product for this profile.</code>         | <code>Insurance Product:<br>- M√£ s·∫£n ph·∫©m: P04<br>- T√™n s·∫£n ph·∫©m: B·∫£o hi·ªÉm Li√™n k·∫øt ƒê·∫ßu t∆∞<br>- M√¥ t·∫£: ƒê·ªëi t∆∞·ª£ng ph√π h·ª£p: Kh√°ch h√†ng c√≥ kh·∫©u v·ªã r·ªßi ro, am hi·ªÉu v·ªÅ ƒë·∫ßu t∆∞ v√† mong mu·ªën gia tƒÉng t√†i s·∫£n m·ªôt c√°ch linh ho·∫°t th√¥ng qua c√°c qu·ªπ ƒë·∫ßu t∆∞ chuy√™n nghi·ªáp.<br>Quy·ªÅn l·ª£i ch√≠nh:<br>- Quy·ªÅn l·ª£i b·∫£o v·ªá nh√¢n th·ªç tr∆∞·ªõc c√°c r·ªßi ro kh√¥ng l∆∞·ªùng tr∆∞·ªõc.<br>- Linh ho·∫°t l·ª±a ch·ªçn c√°c qu·ªπ ƒë·∫ßu t∆∞ (c·ªï phi·∫øu, tr√°i phi·∫øu) ƒë·ªÉ t·ªëi ∆∞u h√≥a l·ª£i nhu·∫≠n k·ª≥ v·ªçng.<br>- D·ªÖ d√†ng thay ƒë·ªïi t·ª∑ l·ªá ph√¢n b·ªï ƒë·∫ßu t∆∞, r√∫t ti·ªÅn, ho·∫∑c ƒë√≥ng th√™m ph√≠ ƒë·ªÉ gia tƒÉng gi√° tr·ªã t√†i kho·∫£n.<br>ƒêi·ªÉm n·ªïi b·∫≠t: T·ªëi ƒëa h√≥a ti·ªÅm nƒÉng tƒÉng tr∆∞·ªüng t√†i s·∫£n trong d√†i h·∫°n, ƒë·ªìng th·ªùi v·∫´n duy tr√¨ m·ªôt l·ªõp b·∫£o v·ªá t√†i ch√≠nh c·ªët l√µi.<br>Goal: match to users who would benefit most.</code>                                                                 |
  | <code>User Profile:<br>- M√£ kh√°ch h√†ng: 13586<br>- Tu·ªïi: 45<br>- Gi·ªõi t√≠nh: Nam<br>- T√¨nh tr·∫°ng h√¥n nh√¢n: ƒê√£ k·∫øt h√¥n<br>- S·ªë con: 1<br>- N∆°i ·ªü: H·∫£i Ph√≤ng<br>- Ngh·ªÅ nghi·ªáp: Lao ƒë·ªông t·ª± do<br>- Thu nh·∫≠p/th√°ng: 7000000<br>Goal: find the most suitable insurance product for this profile.</code> | <code>Insurance Product:<br>- M√£ s·∫£n ph·∫©m: P07<br>- T√™n s·∫£n ph·∫©m: B·∫£o hi·ªÉm S·ª©c kh·ªèe cho Gia ƒë√¨nh<br>- M√¥ t·∫£: ƒê·ªëi t∆∞·ª£ng ph√π h·ª£p: C√°c gia ƒë√¨nh c√≥ con nh·ªè, mu·ªën b·∫£o v·ªá s·ª©c kh·ªèe cho t·∫•t c·∫£ th√†nh vi√™n ch·ªâ trong m·ªôt h·ª£p ƒë·ªìng duy nh·∫•t.<br>Quy·ªÅn l·ª£i ch√≠nh:<br>- T·∫•t c·∫£ th√†nh vi√™n trong gia ƒë√¨nh (v·ª£, ch·ªìng, con c√°i) ƒë∆∞·ª£c b·∫£o v·ªá chung tr√™n m·ªôt h·ª£p ƒë·ªìng.<br>- H·∫°n m·ª©c b·∫£o hi·ªÉm chung cho c·∫£ gia ƒë√¨nh ho·∫∑c ri√™ng cho t·ª´ng th√†nh vi√™n.<br>- Bao g·ªìm ƒë·∫ßy ƒë·ªß c√°c quy·ªÅn l·ª£i n·ªôi tr√∫, ngo·∫°i tr√∫, nha khoa.<br>ƒêi·ªÉm n·ªïi b·∫≠t: Ti·∫øt ki·ªám chi ph√≠ v√† qu·∫£n l√Ω thu·∫≠n ti·ªán h∆°n so v·ªõi vi·ªác mua nhi·ªÅu h·ª£p ƒë·ªìng ri√™ng l·∫ª. S·ª± l·ª±a ch·ªçn th√¥ng minh ƒë·ªÉ b·∫£o v·ªá t·ªï ·∫•m c·ªßa b·∫°n.<br>Goal: match to users who would benefit most.</code>                                                                                                        |
  | <code>User Profile:<br>- M√£ kh√°ch h√†ng: 10010<br>- Tu·ªïi: 29<br>- Gi·ªõi t√≠nh: N·ªØ<br>- T√¨nh tr·∫°ng h√¥n nh√¢n: ƒê√£ k·∫øt h√¥n<br>- S·ªë con: 2<br>- N∆°i ·ªü: B√¨nh D∆∞∆°ng<br>- Ngh·ªÅ nghi·ªáp: C√¥ng nh√¢n<br>- Thu nh·∫≠p/th√°ng: 93000000<br>Goal: find the most suitable insurance product for this profile.</code>     | <code>Insurance Product:<br>- M√£ s·∫£n ph·∫©m: P02<br>- T√™n s·∫£n ph·∫©m: B·∫£o hi·ªÉm B·ªánh hi·ªÉm ngh√®o<br>- M√¥ t·∫£: ƒê·ªëi t∆∞·ª£ng ph√π h·ª£p: Ng∆∞·ªùi tr∆∞·ªüng th√†nh, ƒë·∫∑c bi·ªát l√† tr·ª• c·ªôt kinh t·∫ø trong gia ƒë√¨nh, mu·ªën c√≥ m·ªôt qu·ªπ d·ª± ph√≤ng l·ªõn ƒë·ªÉ ƒë·ªëi ph√≥ v·ªõi c√°c b·ªánh l√Ω nghi√™m tr·ªçng.<br>Quy·ªÅn l·ª£i ch√≠nh:<br>- Chi tr·∫£ m·ªôt l·∫ßn to√†n b·ªô s·ªë ti·ªÅn b·∫£o hi·ªÉm ngay khi c√≥ ch·∫©n ƒëo√°n m·∫Øc m·ªôt trong c√°c b·ªánh hi·ªÉm ngh√®o theo danh m·ª•c (ung th∆∞, ƒë·ªôt qu·ªµ, suy th·∫≠n, ...).<br>- H·ªó tr·ª£ t√†i ch√≠nh k·ªãp th·ªùi ƒë·ªÉ trang tr·∫£i chi ph√≠ ƒëi·ªÅu tr·ªã ƒë·∫Øt ƒë·ªè v√† b√π ƒë·∫Øp thu nh·∫≠p b·ªã m·∫•t.<br>- Quy·ªÅn l·ª£i c√≥ th·ªÉ ƒë∆∞·ª£c chi tr·∫£ ·ªü nhi·ªÅu giai ƒëo·∫°n b·ªánh kh√°c nhau.<br>ƒêi·ªÉm n·ªïi b·∫≠t: Ph√≠ b·∫£o hi·ªÉm h·ª£p l√Ω, quy·ªÅn l·ª£i chi tr·∫£ l·ªõn, gi√∫p b·∫°n an t√¢m chi·∫øn ƒë·∫•u v·ªõi b·ªánh t·∫≠t m√† kh√¥ng ph·∫£i lo l·∫Øng v·ªÅ g√°nh n·∫∑ng t√†i ch√≠nh.<br>Goal: match to users who would benefit most.</code> |
* Loss: [<code>MultipleNegativesRankingLoss</code>](https://sbert.net/docs/package_reference/sentence_transformer/losses.html#multiplenegativesrankingloss) with these parameters:
  ```json
  {
      "scale": 20.0,
      "similarity_fct": "cos_sim",
      "gather_across_devices": false
  }
  ```

### Training Hyperparameters
#### Non-Default Hyperparameters

- `per_device_train_batch_size`: 128
- `per_device_eval_batch_size`: 128
- `num_train_epochs`: 10
- `multi_dataset_batch_sampler`: round_robin

#### All Hyperparameters
<details><summary>Click to expand</summary>

- `overwrite_output_dir`: False
- `do_predict`: False
- `eval_strategy`: no
- `prediction_loss_only`: True
- `per_device_train_batch_size`: 128
- `per_device_eval_batch_size`: 128
- `per_gpu_train_batch_size`: None
- `per_gpu_eval_batch_size`: None
- `gradient_accumulation_steps`: 1
- `eval_accumulation_steps`: None
- `torch_empty_cache_steps`: None
- `learning_rate`: 5e-05
- `weight_decay`: 0.0
- `adam_beta1`: 0.9
- `adam_beta2`: 0.999
- `adam_epsilon`: 1e-08
- `max_grad_norm`: 1
- `num_train_epochs`: 10
- `max_steps`: -1
- `lr_scheduler_type`: linear
- `lr_scheduler_kwargs`: {}
- `warmup_ratio`: 0.0
- `warmup_steps`: 0
- `log_level`: passive
- `log_level_replica`: warning
- `log_on_each_node`: True
- `logging_nan_inf_filter`: True
- `save_safetensors`: True
- `save_on_each_node`: False
- `save_only_model`: False
- `restore_callback_states_from_checkpoint`: False
- `no_cuda`: False
- `use_cpu`: False
- `use_mps_device`: False
- `seed`: 42
- `data_seed`: None
- `jit_mode_eval`: False
- `use_ipex`: False
- `bf16`: False
- `fp16`: False
- `fp16_opt_level`: O1
- `half_precision_backend`: auto
- `bf16_full_eval`: False
- `fp16_full_eval`: False
- `tf32`: None
- `local_rank`: 0
- `ddp_backend`: None
- `tpu_num_cores`: None
- `tpu_metrics_debug`: False
- `debug`: []
- `dataloader_drop_last`: False
- `dataloader_num_workers`: 0
- `dataloader_prefetch_factor`: None
- `past_index`: -1
- `disable_tqdm`: False
- `remove_unused_columns`: True
- `label_names`: None
- `load_best_model_at_end`: False
- `ignore_data_skip`: False
- `fsdp`: []
- `fsdp_min_num_params`: 0
- `fsdp_config`: {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}
- `fsdp_transformer_layer_cls_to_wrap`: None
- `accelerator_config`: {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}
- `parallelism_config`: None
- `deepspeed`: None
- `label_smoothing_factor`: 0.0
- `optim`: adamw_torch_fused
- `optim_args`: None
- `adafactor`: False
- `group_by_length`: False
- `length_column_name`: length
- `ddp_find_unused_parameters`: None
- `ddp_bucket_cap_mb`: None
- `ddp_broadcast_buffers`: False
- `dataloader_pin_memory`: True
- `dataloader_persistent_workers`: False
- `skip_memory_metrics`: True
- `use_legacy_prediction_loop`: False
- `push_to_hub`: False
- `resume_from_checkpoint`: None
- `hub_model_id`: None
- `hub_strategy`: every_save
- `hub_private_repo`: None
- `hub_always_push`: False
- `hub_revision`: None
- `gradient_checkpointing`: False
- `gradient_checkpointing_kwargs`: None
- `include_inputs_for_metrics`: False
- `include_for_metrics`: []
- `eval_do_concat_batches`: True
- `fp16_backend`: auto
- `push_to_hub_model_id`: None
- `push_to_hub_organization`: None
- `mp_parameters`: 
- `auto_find_batch_size`: False
- `full_determinism`: False
- `torchdynamo`: None
- `ray_scope`: last
- `ddp_timeout`: 1800
- `torch_compile`: False
- `torch_compile_backend`: None
- `torch_compile_mode`: None
- `include_tokens_per_second`: False
- `include_num_input_tokens_seen`: False
- `neftune_noise_alpha`: None
- `optim_target_modules`: None
- `batch_eval_metrics`: False
- `eval_on_start`: False
- `use_liger_kernel`: False
- `liger_kernel_config`: None
- `eval_use_gather_object`: False
- `average_tokens_across_devices`: False
- `prompts`: None
- `batch_sampler`: batch_sampler
- `multi_dataset_batch_sampler`: round_robin
- `router_mapping`: {}
- `learning_rate_mapping`: {}

</details>

### Training Logs
| Epoch  | Step | Training Loss |
|:------:|:----:|:-------------:|
| 3.1847 | 500  | 4.8131        |
| 6.3694 | 1000 | 4.7814        |
| 9.5541 | 1500 | 4.772         |


### Framework Versions
- Python: 3.10.18
- Sentence Transformers: 5.1.1
- Transformers: 4.56.2
- PyTorch: 2.8.0+cu129
- Accelerate: 1.10.1
- Datasets: 4.1.1
- Tokenizers: 0.22.1

## Citation

### BibTeX

#### Sentence Transformers
```bibtex
@inproceedings{reimers-2019-sentence-bert,
    title = "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks",
    author = "Reimers, Nils and Gurevych, Iryna",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
    month = "11",
    year = "2019",
    publisher = "Association for Computational Linguistics",
    url = "https://arxiv.org/abs/1908.10084",
}
```

#### MultipleNegativesRankingLoss
```bibtex
@misc{henderson2017efficient,
    title={Efficient Natural Language Response Suggestion for Smart Reply},
    author={Matthew Henderson and Rami Al-Rfou and Brian Strope and Yun-hsuan Sung and Laszlo Lukacs and Ruiqi Guo and Sanjiv Kumar and Balint Miklos and Ray Kurzweil},
    year={2017},
    eprint={1705.00652},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}
```

<!--
## Glossary

*Clearly define terms in order to be accessible across audiences.*
-->

<!--
## Model Card Authors

*Lists the people who create the model card, providing recognition and accountability for the detailed work that goes into its construction.*
-->

<!--
## Model Card Contact

*Provides a way for people who have updates to the Model Card, suggestions, or questions, to contact the Model Card authors.*
-->